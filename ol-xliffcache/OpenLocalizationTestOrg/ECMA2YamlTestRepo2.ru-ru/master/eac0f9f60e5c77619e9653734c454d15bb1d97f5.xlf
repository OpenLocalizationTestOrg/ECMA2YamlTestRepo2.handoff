<?xml version="1.0"?>
<xliff version="1.2" xmlns="urn:oasis:names:tc:xliff:document:1.2" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="urn:oasis:names:tc:xliff:document:1.2 xliff-core-1.2-transitional.xsd">
  <file datatype="xml" original="markdown" source-language="en-US" target-language="ru-ru">
    <header>
      <tool tool-id="mdxliff" tool-name="mdxliff" tool-version="1.0-192e1fd" tool-company="Microsoft" />
      <xliffext:olfilehash xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">eac0f9f60e5c77619e9653734c454d15bb1d97f5</xliffext:olfilehash>
      <xliffext:olfilepath xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">fulldocset\System.Speech.Recognition.RecognizerState.yml</xliffext:olfilepath>
      <xliffext:oltranslationpriority xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">fulldocset</xliffext:oltranslationpriority>
      <xliffext:oltranslationtype xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">Human Translation</xliffext:oltranslationtype>
      <xliffext:olskeletonhash xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">386fc26107cc0d820a512ad56e94df72fb24a099</xliffext:olskeletonhash>
      <xliffext:olxliffhash xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">50a60284e487e541e46eca67e2ffd6431de052bc</xliffext:olxliffhash>
    </header>
    <body>
      <group id="content" extype="content">
        <trans-unit id="101" translate="yes" xml:space="preserve">
          <source>Enumerates values of the recognizer's state.</source>
        </trans-unit>
        <trans-unit id="102" translate="yes" xml:space="preserve" extradata="MT">
          <source>RecognizerState encapsulates the running state of the default speech recognition engine for clients using &lt;xref:System.Speech.Recognition.SpeechRecognizer&gt; to access the Windows Desktop Speech Recognition Technology service.</source>
        </trans-unit>
        <trans-unit id="103" translate="yes" xml:space="preserve" extradata="MT">
          <source>Applications can obtain the current state of the desktop recognition engine as a RecognizerState object by querying the &lt;xref:System.Speech.Recognition.SpeechRecognizer.State%2A&gt; property on a &lt;xref:System.Speech.Recognition.SpeechRecognizer&gt; instance.</source>
        </trans-unit>
        <trans-unit id="104" translate="yes" xml:space="preserve" extradata="MT">
          <source>To obtain the state of the desktop recognition engine after it changes, applications can query the &lt;xref:System.Speech.Recognition.StateChangedEventArgs.RecognizerState%2A&gt; property of the &lt;xref:System.Speech.Recognition.StateChangedEventArgs&gt; object passed to a handler for &lt;xref:System.Speech.Recognition.SpeechRecognizer.StateChanged&gt; events.</source>
        </trans-unit>
        <trans-unit id="105" translate="yes" xml:space="preserve" extradata="MT">
          <source>&gt; <ph id="ph1">[!NOTE]</ph> &gt;  &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine&gt; instances run in-process and their running state is under the control of the application.</source>
        </trans-unit>
        <trans-unit id="106" translate="yes" xml:space="preserve" extradata="MT">
          <source>Therefore, &lt;xref:System.Speech.Recognition.SpeechRecognitionEngine&gt; does not contain a property to return a RecognizerState object.</source>
        </trans-unit>
        <trans-unit id="107" translate="yes" xml:space="preserve" extradata="MT">
          <source>The state of a desktop speech recognition server is a read-only property and cannot be controlled programmatically.</source>
        </trans-unit>
        <trans-unit id="108" translate="yes" xml:space="preserve" extradata="MT">
          <source>Users can change a shared speech recognizer's state using the Speech Recognition user interface (UI) or through the <bpt id="p1">**</bpt>Speech Recognition<ept id="p1">**</ept> member of the Windows <bpt id="p2">**</bpt>Control Panel<ept id="p2">**</ept>.</source>
        </trans-unit>
        <trans-unit id="109" translate="yes" xml:space="preserve" extradata="MT">
          <source>Both the <bpt id="p1">**</bpt>On<ept id="p1">**</ept> and <bpt id="p2">**</bpt>Sleep<ept id="p2">**</ept> settings in the Speech Recognition UI correspond to the <ph id="ph1">`Listening`</ph> state.</source>
        </trans-unit>
        <trans-unit id="110" translate="yes" xml:space="preserve" extradata="MT">
          <source>The <bpt id="p1">**</bpt>Off<ept id="p1">**</ept> setting in the Speech Recognition UI corresponds to Stopped.</source>
        </trans-unit>
        <trans-unit id="111" translate="yes" xml:space="preserve" extradata="MT">
          <source>&lt;xref:System.Speech.Recognition.SpeechRecognizer.Enabled%2A&gt; is the other property that affects the readiness of a shared speech recognition engine to receive and process speech input.</source>
        </trans-unit>
        <trans-unit id="112" translate="yes" xml:space="preserve" extradata="MT">
          <source>You can use &lt;xref:System.Speech.Recognition.SpeechRecognizer.Enabled%2A&gt; to control whether or not a shared speech recognition engine's grammars are active for recognition.</source>
        </trans-unit>
        <trans-unit id="113" translate="yes" xml:space="preserve" extradata="MT">
          <source>However, changing the &lt;xref:System.Speech.Recognition.SpeechRecognizer.Enabled%2A&gt; property has no effect on the RecognizerState property.</source>
        </trans-unit>
        <trans-unit id="114" translate="yes" xml:space="preserve" extradata="MT">
          <source>Information such as the description, the supported culture and audio formats, and the recognition engine name is encapsulated in the &lt;xref:System.Speech.Recognition.RecognizerInfo&gt; type.</source>
        </trans-unit>
        <trans-unit id="115" translate="yes" xml:space="preserve">
          <source>The recognition engine is available to receive and analyze audio input.</source>
        </trans-unit>
        <trans-unit id="116" translate="yes" xml:space="preserve">
          <source>To be added.</source>
        </trans-unit>
        <trans-unit id="117" translate="yes" xml:space="preserve">
          <source>The recognition engine is not receiving or analyzing audio input.</source>
        </trans-unit>
        <trans-unit id="118" translate="yes" xml:space="preserve">
          <source>To be added.</source>
        </trans-unit>
      </group>
    </body>
  </file>
</xliff>